{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text   Language   Country\n",
      "0    МОНГОЛ УЛСЫН ХУУЛЬ\\n2017 оны 02 сарын 02 өдөр\\...  Mongolian  Mongolia\n",
      "1    2 дугаар зүйл.Гамшгаас хамгаалах тухай хууль т...  Mongolian  Mongolia\n",
      "2    2.2.Монгол Улсын олон улсын гэрээнд энэ хуульд...  Mongolian  Mongolia\n",
      "3    3 дугаар зүйл.Хуулийн үйлчлэх хүрээ\\n3.1.Энэ х...  Mongolian  Mongolia\n",
      "4    /Энэ хэсэгт 2020 оны 05 дугаар сарын 14-ний өд...  Mongolian  Mongolia\n",
      "..                                                 ...        ...       ...\n",
      "225  51.2.Гамшгаас хамгаалах, эрсдэлийг бууруулах а...  Mongolian  Mongolia\n",
      "226  /Энэ хэсгийг 2020 оны 05 дугаар сарын 14-ний ө...  Mongolian  Mongolia\n",
      "227  /Энэ хэсгийг 2020 оны 05 дугаар сарын 14-ний ө...  Mongolian  Mongolia\n",
      "228  АРВАННЭГДҮГЭЭР БҮЛЭГ\\nБУСАД ЗҮЙЛ\\n52 дугаар зү...  Mongolian  Mongolia\n",
      "229  /Энэ хэсэгт 2020 оны 05 дугаар сарын 14-ний өд...  Mongolian  Mongolia\n",
      "\n",
      "[230 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/pratimathapa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "with open('/home/pratimathapa/code/PratimaThapa/DisLex_Project/pkl files/text_mongolian.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "# Function to split text into sentences and duplicate rows\n",
    "def split_text_into_sentences(df):\n",
    "    sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Text']\n",
    "        language = row['Language']\n",
    "        country = row['Country']\n",
    "        # Tokenize text into sentences\n",
    "        text_sentences = nltk.sent_tokenize(text)\n",
    "        for sentence in text_sentences:\n",
    "            # Append each sentence with Language and Country\n",
    "            sentences.append({'Text': sentence, 'Language': language, 'Country': country})\n",
    "    # Create a new DataFrame from the list of sentences\n",
    "    new_df = pd.DataFrame(sentences)\n",
    "    return new_df\n",
    "\n",
    "# Call the function to split text into sentences\n",
    "new_dataframe = split_text_into_sentences(df)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence   Language   Country\n",
      "21  \"хязгаарлалтын дэглэм\" гэж засаг захиргаа, нут...  Mongolian  Mongolia\n",
      "22  \"бэлэн байдал\" гэж гамшиг, аюулын сөрөг үр даг...  Mongolian  Mongolia\n",
      "23  \"Бүтцийн арга хэмжээ\" гэж барилга байгууламж, ...  Mongolian  Mongolia\n",
      "24  \"Бүтцийн бус арга хэмжээ\" гэж хууль тогтоомж, ...  Mongolian  Mongolia\n",
      "25  /Энэ хэсгийг 2020 оны 05 дугаар сарын 14-ний ө...  Mongolian  Mongolia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/pratimathapa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "with open('/home/pratimathapa/code/PratimaThapa/DisLex_Project/pkl files/text_mongolian.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "# Function to clean text, split it into sentences, and duplicate rows\n",
    "def clean_text_split_into_sentences(df):\n",
    "    sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Text']\n",
    "        language = row['Language']\n",
    "        country = row['Country']\n",
    "        # Clean text: remove \\n and \\t\n",
    "        text = text.replace('\\n', '').replace('\\t', '')\n",
    "        # Tokenize text into sentences\n",
    "        text_sentences = nltk.sent_tokenize(text)\n",
    "        for sentence in text_sentences:\n",
    "            # Append each sentence with Language and Country\n",
    "            sentences.append({'Sentence': sentence, 'Language': language, 'Country': country})\n",
    "    # Create a new DataFrame from the list of sentences\n",
    "    new_df = pd.DataFrame(sentences)\n",
    "    return new_df\n",
    "\n",
    "# Call the function to clean text, split into sentences, and duplicate rows\n",
    "new_dataframe = clean_text_split_into_sentences(df)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_dataframe.tail())\n",
    "\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "#new_dataframe.to_excel('/home/pratimathapa/code/PratimaThapa/DisLex_Project/xlsx_files/Mongolia.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dislex_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
